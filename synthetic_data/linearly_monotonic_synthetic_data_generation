import numpy as np
import pandas as pd
# ──────────────────────────────────────────────────────────────────────────────
# 1) Configuration
np.random.seed(42)
n_samples = 5000
# 2) Generate monotonic features
#    Each feature is drawn uniform, but contributes linearly to the target.
downtown_downtown = np.random.uniform(0, 1, size=n_samples)      # ∈ [0,1]
EmpDen_Des        = np.random.uniform(100, 1000, size=n_samples) # ∈ [100,1000]
EmpDen_Ori        = np.random.uniform(100, 1000, size=n_samples)
Commuters_HW      = np.random.uniform(0, 500, size=n_samples)
Commuters_WH      = np.random.uniform(0, 500, size=n_samples)
# 3) Build a strictly monotonic target
#    Coefficients chosen so each feature has positive effect on "trips".
#    Add Gaussian noise to simulate real‐world variation.
coeffs = {
    'downtown_downtown':  50.0,
    'EmpDen_Des':          0.08,
    'EmpDen_Ori':          0.06,
    'Commuters_HW':        0.10,
    'Commuters_WH':        0.12,
}
noise = np.random.normal(0, 5, size=n_samples)
total_number_trips = (
    coeffs['downtown_downtown'] * downtown_downtown +
    coeffs['EmpDen_Des']        * EmpDen_Des        +
    coeffs['EmpDen_Ori']        * EmpDen_Ori        +
    coeffs['Commuters_HW']      * Commuters_HW      +
    coeffs['Commuters_WH']      * Commuters_WH      +
    noise
)
# 4) Assemble into a DataFrame
df_synth = pd.DataFrame({
    'downtown_downtown': downtown_downtown,
    'EmpDen_Des':        EmpDen_Des,
    'EmpDen_Ori':        EmpDen_Ori,
    'Commuters_HW':      Commuters_HW,
    'Commuters_WH':      Commuters_WH,
    'total_number_trips': total_number_trips
})
# 5) (Optional) Save to CSV
df_synth.to_csv('synthetic_monotonic_trips.csv', index=False)
# 6) Quick sanity‐check
print(df_synth.head())
print("\nCorrelation with total_number_trips:")
print(df_synth.corr()['total_number_trips'].drop('total_number_trips'))
